#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - Ultra Detailed Analysis Engine REAL
Motor de an√°lise GIGANTE ultra-detalhado - SEM SIMULA√á√ÉO OU FALLBACK
"""

import os
import logging
import time
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
from services.ai_manager import ai_manager
from services.production_search_manager import production_search_manager
from services.production_content_extractor import production_content_extractor
from services.mental_drivers_architect import mental_drivers_architect
from services.visual_proofs_generator import visual_proofs_generator
from services.anti_objection_system import anti_objection_system
from services.pre_pitch_architect import pre_pitch_architect
from services.future_prediction_engine import future_prediction_engine

logger = logging.getLogger(__name__)

class UltraDetailedAnalysisEngine:
    """Motor de an√°lise GIGANTE ultra-detalhado - ZERO SIMULA√á√ÉO"""

    def __init__(self):
        """Inicializa o motor de an√°lise GIGANTE"""
        self.min_content_threshold = 30000  # M√≠nimo 30k caracteres
        self.min_sources_threshold = 10     # M√≠nimo 10 fontes reais
        self.quality_threshold = 85.0       # Score m√≠nimo de qualidade

        logger.info("üöÄ Ultra Detailed Analysis Engine GIGANTE inicializado - ZERO TOLER√ÇNCIA A SIMULA√á√ÉO")

    def generate_gigantic_analysis(
        self, 
        data: Dict[str, Any],
        session_id: Optional[str] = None,
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """Gera an√°lise GIGANTE ultra-detalhada - FALHA SE DADOS INSUFICIENTES"""

        start_time = time.time()
        logger.info(f"üöÄ INICIANDO AN√ÅLISE GIGANTE para {data.get('segmento')}")

        if progress_callback:
            progress_callback(1, "üîç Validando dados de entrada...")

        # VALIDA√á√ÉO CR√çTICA - FALHA SE INSUFICIENTE
        validation_result = self._validate_input_data(data)
        if not validation_result['valid']:
            raise Exception(f"DADOS INSUFICIENTES: {validation_result['message']}")

        try:
            # FASE 1: PESQUISA WEB MASSIVA REAL
            if progress_callback:
                progress_callback(2, "üåê Executando pesquisa web massiva REAL...")

            research_data = self._execute_massive_real_research(data, progress_callback)

            # VALIDA√á√ÉO CR√çTICA - FALHA SE PESQUISA INSUFICIENTE
            if not self._validate_research_quality(research_data):
                raise Exception("PESQUISA INSUFICIENTE: N√£o foi poss√≠vel coletar dados reais suficientes da web")

            # FASE 2: AN√ÅLISE COM IA REAL
            if progress_callback:
                progress_callback(4, "üß† Analisando com m√∫ltiplas IAs REAIS...")

            ai_analysis = self._execute_real_ai_analysis(data, research_data, progress_callback)

            # VALIDA√á√ÉO CR√çTICA - FALHA SE IA N√ÉO RESPONDER
            if not ai_analysis or not self._validate_ai_response(ai_analysis):
                raise Exception("IA FALHOU: N√£o foi poss√≠vel gerar an√°lise v√°lida com IA")

            # FASE 3: SISTEMAS AVAN√áADOS REAIS
            if progress_callback:
                progress_callback(6, "üß† Gerando drivers mentais customizados...")

            mental_drivers = self._generate_real_mental_drivers(ai_analysis, data)

            if progress_callback:
                progress_callback(7, "üé≠ Criando provas visuais instant√¢neas...")

            visual_proofs = self._generate_real_visual_proofs(ai_analysis, data)

            if progress_callback:
                progress_callback(8, "üõ°Ô∏è Construindo sistema anti-obje√ß√£o...")

            anti_objection = self._generate_real_anti_objection(ai_analysis, data)

            if progress_callback:
                progress_callback(9, "üéØ Arquitetando pr√©-pitch invis√≠vel...")

            pre_pitch = self._generate_real_pre_pitch(ai_analysis, mental_drivers, data)

            if progress_callback:
                progress_callback(10, "üîÆ Predizendo futuro do mercado...")

            future_predictions = self._generate_real_future_predictions(data, research_data)

            # FASE 4: CONSOLIDA√á√ÉO FINAL
            if progress_callback:
                progress_callback(12, "‚ú® Consolidando an√°lise GIGANTE...")

            final_analysis = self._consolidate_gigantic_analysis(
                data, research_data, ai_analysis, mental_drivers, 
                visual_proofs, anti_objection, pre_pitch, future_predictions
            )

            # VALIDA√á√ÉO FINAL CR√çTICA
            quality_score = self._calculate_final_quality_score(final_analysis)
            if quality_score < self.quality_threshold:
                raise Exception(f"QUALIDADE INSUFICIENTE: Score {quality_score:.1f} < {self.quality_threshold}")

            end_time = time.time()
            processing_time = end_time - start_time

            # Adiciona metadados finais
            final_analysis['metadata'] = {
                'processing_time_seconds': processing_time,
                'processing_time_formatted': f"{int(processing_time // 60)}m {int(processing_time % 60)}s",
                'analysis_engine': 'ARQV30 Enhanced v2.0 - GIGANTE MODE',
                'generated_at': datetime.utcnow().isoformat(),
                'quality_score': quality_score,
                'report_type': 'GIGANTE_ULTRA_DETALHADO',
                'simulation_free_guarantee': True,
                'real_data_sources': len(research_data.get('sources', [])),
                'total_content_analyzed': research_data.get('total_content_length', 0),
                'ai_models_used': 3,
                'advanced_systems_included': True
            }

            if progress_callback:
                progress_callback(13, "üéâ An√°lise GIGANTE conclu√≠da com sucesso!")

            logger.info(f"‚úÖ An√°lise GIGANTE conclu√≠da - Score: {quality_score:.1f} - Tempo: {processing_time:.2f}s")
            return final_analysis

        except Exception as e:
            logger.error(f"‚ùå FALHA CR√çTICA na an√°lise GIGANTE: {str(e)}")
            # N√ÉO GERA FALLBACK - FALHA EXPLICITAMENTE
            raise Exception(f"AN√ÅLISE FALHOU: {str(e)}. Configure APIs corretamente e tente novamente.")

    def _validate_input_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Valida dados de entrada - FALHA SE INSUFICIENTE"""

        required_fields = ['segmento']
        missing_fields = [field for field in required_fields if not data.get(field)]

        if missing_fields:
            return {
                'valid': False,
                'message': f"Campos obrigat√≥rios ausentes: {', '.join(missing_fields)}"
            }

        # Valida qualidade dos dados
        segmento = data.get('segmento', '').strip()
        if len(segmento) < 3:
            return {
                'valid': False,
                'message': "Segmento deve ter pelo menos 3 caracteres"
            }

        return {'valid': True, 'message': 'Dados v√°lidos'}

    def _execute_massive_real_research(
        self, 
        data: Dict[str, Any], 
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """Executa pesquisa web massiva REAL - FALHA SE INSUFICIENTE"""

        logger.info("üåê INICIANDO PESQUISA WEB MASSIVA REAL")

        # Gera queries de pesquisa inteligentes
        queries = self._generate_intelligent_queries(data)

        all_results = []
        extracted_content = []
        total_content_length = 0

        for i, query in enumerate(queries):
            if progress_callback:
                progress_callback(2, f"üîç Pesquisando: {query[:50]}...", f"Query {i+1}/{len(queries)}")

            try:
                # Busca com m√∫ltiplos provedores
                search_results = production_search_manager.search_with_fallback(query, max_results=15)

                if not search_results:
                    logger.warning(f"‚ö†Ô∏è Query '{query}' retornou 0 resultados")
                    continue

                all_results.extend(search_results)

                # Extrai conte√∫do das URLs encontradas
                logger.info(f"üìÑ Extraindo conte√∫do de {len(search_results)} URLs...")
                extracted_contents = []

                for result in search_results[:15]:  # Limita a 15 URLs para performance
                    try:
                        # Usa o novo extrator robusto
                        content = production_content_extractor.extract_content(result['url'])
                        if content and len(content) >= 500:  # M√≠nimo 500 caracteres
                            extracted_contents.append({
                                'url': result['url'],
                                'title': result.get('title', 'Sem t√≠tulo'),
                                'content': content[:3000],  # Limita tamanho
                                'snippet': result.get('snippet', '')
                            })
                            logger.info(f"‚úÖ Conte√∫do extra√≠do de {result['url']}: {len(content)} caracteres")
                        else:
                            logger.warning(f"‚ö†Ô∏è Conte√∫do insuficiente de {result['url']}: {len(content) if content else 0} < 500")
                    except Exception as e:
                        logger.error(f"‚ùå Erro ao extrair {result['url']}: {str(e)}")
                        continue

                if len(extracted_contents) == 0:
                    logger.error("‚ùå FALHA CR√çTICA: Nenhum conte√∫do extra√≠do das URLs de busca")
                    raise RuntimeError(f"Falha cr√≠tica: n√£o foi poss√≠vel extrair conte√∫do real de nenhuma URL para '{query}'. Sistema n√£o pode gerar an√°lise com dados insuficientes.")

                # Adiciona conte√∫do extra√≠do
                for item in extracted_contents:
                    total_content_length += len(item['content'])
                    extracted_content.append(item)

                time.sleep(1)  # Rate limiting

            except Exception as e:
                logger.error(f"‚ùå Erro na query '{query}': {str(e)}")
                continue

        # Remove duplicatas
        unique_content = []
        seen_urls = set()
        for content_item in extracted_content:
            if content_item['url'] not in seen_urls:
                seen_urls.add(content_item['url'])
                unique_content.append(content_item)

        # Ordena por relev√¢ncia
        unique_content.sort(key=lambda x: x['relevance_score'], reverse=True)

        research_data = {
            'queries_executed': queries,
            'total_queries': len(queries),
            'total_results': len(all_results),
            'unique_sources': len(unique_content),
            'total_content_length': total_content_length,
            'extracted_content': unique_content,
            'sources': [{'url': item['url'], 'title': item['title'], 'source': item['source']} for item in unique_content],
            'research_timestamp': datetime.now().isoformat()
        }

        logger.info(f"‚úÖ Pesquisa massiva: {len(unique_content)} p√°ginas, {total_content_length:,} caracteres")
        return research_data

    def _generate_intelligent_queries(self, data: Dict[str, Any]) -> List[str]:
        """Gera queries inteligentes para pesquisa"""

        segmento = data.get('segmento', '')
        produto = data.get('produto', '')
        publico = data.get('publico', '')

        base_queries = []

        # Queries principais
        if produto:
            base_queries.extend([
                f"mercado {segmento} {produto} Brasil 2024 dados estat√≠sticas",
                f"an√°lise competitiva {segmento} {produto} oportunidades",
                f"tend√™ncias {segmento} {produto} crescimento futuro"
            ])
        else:
            base_queries.extend([
                f"mercado {segmento} Brasil 2024 dados estat√≠sticas crescimento",
                f"an√°lise competitiva {segmento} principais empresas",
                f"tend√™ncias {segmento} oportunidades investimento"
            ])

        # Queries espec√≠ficas por p√∫blico
        if publico:
            base_queries.extend([
                f"comportamento consumidor {publico} {segmento} pesquisa",
                f"perfil demogr√°fico {publico} Brasil dados"
            ])

        # Queries de intelig√™ncia de mercado
        base_queries.extend([
            f"startups {segmento} investimento venture capital Brasil",
            f"regulamenta√ß√£o {segmento} mudan√ßas legais impacto",
            f"inova√ß√£o tecnol√≥gica {segmento} disrup√ß√£o",
            f"cases sucesso empresas {segmento} brasileiras",
            f"desafios principais {segmento} solu√ß√µes mercado"
        ])

        return base_queries[:12]  # M√°ximo 12 queries para otimiza√ß√£o

    def _validate_research_quality(self, research_data: Dict[str, Any]) -> bool:
        """Valida qualidade da pesquisa - FALHA SE INSUFICIENTE"""

        total_content = research_data.get('total_content_length', 0)
        unique_sources = research_data.get('unique_sources', 0)

        if total_content < self.min_content_threshold:
            logger.error(f"‚ùå Conte√∫do insuficiente: {total_content} < {self.min_content_threshold}")
            return False

        if unique_sources < self.min_sources_threshold:
            logger.error(f"‚ùå Fontes insuficientes: {unique_sources} < {self.min_sources_threshold}")
            return False

        return True

    def _execute_real_ai_analysis(
        self, 
        data: Dict[str, Any], 
        research_data: Dict[str, Any],
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """Executa an√°lise com IA REAL - FALHA SE IA N√ÉO RESPONDER"""

        # Prepara contexto de pesquisa REAL
        search_context = self._prepare_search_context(research_data)

        # Constr√≥i prompt ULTRA-DETALHADO
        prompt = self._build_gigantic_analysis_prompt(data, search_context)

        logger.info("ü§ñ Executando an√°lise com IA REAL...")

        # Executa com AI Manager (sistema de fallback autom√°tico)
        ai_response = ai_manager.generate_analysis(prompt, max_tokens=8192)

        if not ai_response:
            raise Exception("IA N√ÉO RESPONDEU: Nenhum provedor de IA dispon√≠vel ou funcionando")

        # Processa resposta da IA
        processed_analysis = self._process_ai_response_strict(ai_response, data)

        return processed_analysis

    def _prepare_search_context(self, research_data: Dict[str, Any]) -> str:
        """Prepara contexto de pesquisa para IA"""

        extracted_content = research_data.get('extracted_content', [])

        if not extracted_content:
            raise Exception("NENHUM CONTE√öDO EXTRA√çDO: Pesquisa web falhou completamente")

        # Combina conte√∫do das p√°ginas mais relevantes
        context = "PESQUISA WEB MASSIVA REAL EXECUTADA:\n\n"

        for i, content_item in enumerate(extracted_content[:15], 1):  # Top 15 p√°ginas
            context += f"--- FONTE REAL {i}: {content_item['title']} ---\n"
            context += f"URL: {content_item['url']}\n"
            context += f"Relev√¢ncia: {content_item['relevance_score']:.2f}\n"
            context += f"Conte√∫do: {content_item['content'][:2000]}\n\n"

        # Adiciona estat√≠sticas da pesquisa
        context += f"\n=== ESTAT√çSTICAS DA PESQUISA REAL ===\n"
        context += f"Total de queries executadas: {research_data.get('total_queries', 0)}\n"
        context += f"Total de resultados encontrados: {research_data.get('total_results', 0)}\n"
        context += f"P√°ginas √∫nicas analisadas: {research_data.get('unique_sources', 0)}\n"
        context += f"Total de caracteres extra√≠dos: {research_data.get('total_content_length', 0):,}\n"
        context += f"Garantia de dados reais: 100%\n"

        return context

    def _build_gigantic_analysis_prompt(self, data: Dict[str, Any], search_context: str) -> str:
        """Constr√≥i prompt GIGANTE para an√°lise ultra-detalhada"""

        prompt = f"""
# AN√ÅLISE GIGANTE ULTRA-DETALHADA - ARQV30 ENHANCED v2.0

Voc√™ √© o DIRETOR SUPREMO DE AN√ÅLISE DE MERCADO GIGANTE, especialista de elite com 30+ anos de experi√™ncia.

## DADOS REAIS DO PROJETO:
- **Segmento**: {data.get('segmento', 'N√£o informado')}
- **Produto/Servi√ßo**: {data.get('produto', 'N√£o informado')}
- **P√∫blico-Alvo**: {data.get('publico', 'N√£o informado')}
- **Pre√ßo**: R$ {data.get('preco', 'N√£o informado')}
- **Objetivo de Receita**: R$ {data.get('objetivo_receita', 'N√£o informado')}
- **Or√ßamento Marketing**: R$ {data.get('orcamento_marketing', 'N√£o informado')}
- **Prazo**: {data.get('prazo_lancamento', 'N√£o informado')}
- **Concorrentes**: {data.get('concorrentes', 'N√£o informado')}
- **Dados Adicionais**: {data.get('dados_adicionais', 'N√£o informado')}

## CONTEXTO DE PESQUISA REAL:
{search_context[:15000]}

## INSTRU√á√ïES CR√çTICAS:

RETORNE APENAS UM JSON V√ÅLIDO. N√ÉO INCLUA EXPLICA√á√ïES, TEXTOS OU MARKDOWN. 
COMECE COM {{ E TERMINE COM }}.

Use APENAS dados REAIS da pesquisa fornecida. NUNCA invente ou simule informa√ß√µes.

```json
{{
  "avatar_ultra_detalhado": {{
    "nome_ficticio": "Nome representativo baseado em dados reais",
    "perfil_demografico": {{
      "idade": "Faixa et√°ria espec√≠fica com dados reais",
      "genero": "Distribui√ß√£o real por g√™nero",
      "renda": "Faixa de renda real baseada em pesquisas",
      "escolaridade": "N√≠vel educacional real",
      "localizacao": "Regi√µes geogr√°ficas reais",
      "estado_civil": "Status relacionamento real",
      "profissao": "Ocupa√ß√µes reais mais comuns"
    }},
    "perfil_psicografico": {{
      "personalidade": "Tra√ßos reais dominantes",
      "valores": "Valores reais e cren√ßas principais",
      "interesses": "Hobbies e interesses reais espec√≠ficos",
      "estilo_vida": "Como realmente vive baseado em pesquisas",
      "comportamento_compra": "Processo real de decis√£o",
      "influenciadores": "Quem realmente influencia decis√µes",
      "medos_profundos": "Medos reais documentados",
      "aspiracoes_secretas": "Aspira√ß√µes reais baseadas em estudos"
    }},
    "dores_viscerais": [
      "Lista de 12-15 dores espec√≠ficas e REAIS baseadas em pesquisas"
    ],
    "desejos_secretos": [
      "Lista de 12-15 desejos profundos REAIS baseados em estudos"
    ],
    "objecoes_reais": [
      "Lista de 10-12 obje√ß√µes REAIS espec√≠ficas baseadas em dados"
    ],
    "jornada_emocional": {{
      "consciencia": "Como realmente toma consci√™ncia",
      "consideracao": "Processo real de avalia√ß√£o",
      "decisao": "Fatores reais decisivos",
      "pos_compra": "Experi√™ncia real p√≥s-compra"
    }},
    "linguagem_interna": {{
      "frases_dor": ["Frases reais que usa"],
      "frases_desejo": ["Frases reais de desejo"],
      "metaforas_comuns": ["Met√°foras reais usadas"],
      "vocabulario_especifico": ["Palavras espec√≠ficas do nicho"],
      "tom_comunicacao": "Tom real de comunica√ß√£o"
    }}
  }},

  "escopo": {{
    "posicionamento_mercado": "Posicionamento √∫nico REAL baseado em an√°lise",
    "proposta_valor": "Proposta REAL irresist√≠vel",
    "diferenciais_competitivos": [
      "Lista de diferenciais REAIS √∫nicos e defens√°veis"
    ],
    "mensagem_central": "Mensagem principal REAL",
    "tom_comunicacao": "Tom de voz REAL ideal",
    "nicho_especifico": "Nicho mais espec√≠fico REAL",
    "estrategia_oceano_azul": "Como criar mercado REAL sem concorr√™ncia",
    "ancoragem_preco": "Como ancorar o pre√ßo REAL"
  }},

  "analise_concorrencia_detalhada": [
    {{
      "nome": "Nome REAL do concorrente principal",
      "analise_swot": {{
        "forcas": ["Principais for√ßas REAIS espec√≠ficas"],
        "fraquezas": ["Principais fraquezas REAIS explor√°veis"],
        "oportunidades": ["Oportunidades REAIS que eles n√£o veem"],
        "ameacas": ["Amea√ßas REAIS que representam"]
      }},
      "estrategia_marketing": "Estrat√©gia REAL principal detalhada",
      "posicionamento": "Como se posicionam REALMENTE",
      "vulnerabilidades": ["Pontos fracos REAIS explor√°veis"],
      "share_mercado_estimado": "Participa√ß√£o REAL estimada"
    }}
  ],

  "estrategia_palavras_chave": {{
    "palavras_primarias": [
      "15-20 palavras-chave REAIS principais com alto volume"
    ],
    "palavras_secundarias": [
      "25-35 palavras-chave REAIS secund√°rias"
    ],
    "long_tail": [
      "30-50 palavras-chave REAIS de cauda longa espec√≠ficas"
    ],
    "intencao_busca": {{
      "informacional": ["Palavras REAIS para conte√∫do educativo"],
      "navegacional": ["Palavras REAIS para encontrar a marca"],
      "transacional": ["Palavras REAIS para convers√£o direta"]
    }},
    "estrategia_conteudo": "Como usar as palavras-chave REALMENTE",
    "sazonalidade": "Varia√ß√µes REAIS sazonais das buscas",
    "oportunidades_seo": "Oportunidades REAIS espec√≠ficas identificadas"
  }},

  "metricas_performance_detalhadas": {{
    "kpis_principais": [
      {{
        "metrica": "Nome da m√©trica REAL",
        "objetivo": "Valor objetivo REAL",
        "frequencia": "Frequ√™ncia de medi√ß√£o",
        "responsavel": "Quem acompanha"
      }}
    ],
    "projecoes_financeiras": {{
      "cenario_conservador": {{
        "receita_mensal": "Valor REAL baseado em dados",
        "clientes_mes": "N√∫mero REAL de clientes",
        "ticket_medio": "Ticket m√©dio REAL",
        "margem_lucro": "Margem REAL esperada"
      }},
      "cenario_realista": {{
        "receita_mensal": "Valor REAL baseado em dados",
        "clientes_mes": "N√∫mero REAL de clientes",
        "ticket_medio": "Ticket m√©dio REAL",
        "margem_lucro": "Margem REAL esperada"
      }},
      "cenario_otimista": {{
        "receita_mensal": "Valor REAL baseado em dados",
        "clientes_mes": "N√∫mero REAL de clientes",
        "ticket_medio": "Ticket m√©dio REAL",
        "margem_lucro": "Margem REAL esperada"
      }}
    }},
    "roi_esperado": "ROI REAL baseado em dados do mercado",
    "payback_investimento": "Tempo REAL de retorno",
    "lifetime_value": "LTV REAL do cliente"
  }},

  "funil_vendas_detalhado": {{
    "topo_funil": {{
      "objetivo": "Objetivo REAL do topo",
      "estrategias": ["Estrat√©gias REAIS espec√≠ficas"],
      "conteudos": ["Tipos de conte√∫do REAIS"],
      "metricas": ["M√©tricas REAIS a acompanhar"],
      "investimento": "Investimento REAL necess√°rio"
    }},
    "meio_funil": {{
      "objetivo": "Objetivo REAL do meio",
      "estrategias": ["Estrat√©gias REAIS espec√≠ficas"],
      "conteudos": ["Tipos de conte√∫do REAIS"],
      "metricas": ["M√©tricas REAIS a acompanhar"],
      "investimento": "Investimento REAL necess√°rio"
    }},
    "fundo_funil": {{
      "objetivo": "Objetivo REAL do fundo",
      "estrategias": ["Estrat√©gias REAIS espec√≠ficas"],
      "conteudos": ["Tipos de conte√∫do REAIS"],
      "metricas": ["M√©tricas REAIS a acompanhar"],
      "investimento": "Investimento REAL necess√°rio"
    }}
  }},

  "plano_acao_detalhado": {{
    "primeiros_30_dias": {{
      "foco": "Foco REAL dos primeiros 30 dias",
      "atividades": ["Lista de atividades REAIS espec√≠ficas"],
      "investimento": "Investimento REAL necess√°rio",
      "entregas": ["Entregas REAIS esperadas"],
      "metricas": ["M√©tricas REAIS a acompanhar"]
    }},
    "dias_31_60": {{
      "foco": "Foco REAL dos dias 31-60",
      "atividades": ["Lista de atividades REAIS espec√≠ficas"],
      "investimento": "Investimento REAL necess√°rio",
      "entregas": ["Entregas REAIS esperadas"],
      "metricas": ["M√©tricas REAIS a acompanhar"]
    }},
    "dias_61_90": {{
      "foco": "Foco REAL dos dias 61-90",
      "atividades": ["Lista de atividades REAIS espec√≠ficas"],
      "investimento": "Investimento REAL necess√°rio",
      "entregas": ["Entregas REAIS esperadas"],
      "metricas": ["M√©tricas REAIS a acompanhar"]
    }}
  }},

  "insights_exclusivos": [
    "Lista de 25-35 insights √∫nicos, espec√≠ficos e ULTRA-VALIOSOS baseados na an√°lise REAL profunda"
  ]
}}
```

CR√çTICO: Use APENAS dados REAIS da pesquisa fornecida. NUNCA invente ou simule informa√ß√µes.
Se n√£o houver dados suficientes para uma se√ß√£o, retorne "DADOS_INSUFICIENTES" para essa se√ß√£o.
"""

        return prompt

    def _process_ai_response_strict(self, ai_response: str, original_data: Dict[str, Any]) -> Dict[str, Any]:
        """Processa resposta da IA com valida√ß√£o RIGOROSA"""

        try:
            # Remove markdown se presente
            clean_text = ai_response.strip()

            # Extrai JSON do markdown
            if "```json" in clean_text:
                start = clean_text.find("```json") + 7
                end = clean_text.rfind("```")
                clean_text = clean_text[start:end].strip()
            elif "```" in clean_text:
                start = clean_text.find("```") + 3
                end = clean_text.rfind("```")
                clean_text = clean_text[start:end].strip()

            # Tenta parsear JSON
            analysis = json.loads(clean_text)

            # VALIDA√á√ÉO RIGOROSA - FALHA SE SIMULADO
            if self._contains_simulated_data(analysis):
                raise Exception("IA RETORNOU DADOS SIMULADOS: An√°lise cont√©m dados gen√©ricos ou simulados")

            return analysis

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erro ao parsear JSON da IA: {str(e)}")
            logger.error(f"Resposta recebida: {ai_response[:500]}...")
            raise Exception("IA RETORNOU JSON INV√ÅLIDO: N√£o foi poss√≠vel processar resposta da IA")

    def _contains_simulated_data(self, analysis: Dict[str, Any]) -> bool:
        """Verifica se an√°lise cont√©m dados simulados - FALHA SE ENCONTRAR"""

        # Palavras que indicam simula√ß√£o
        simulation_indicators = [
            'n√£o informado', 'n/a', 'exemplo', 'simulado', 'fict√≠cio', 
            'hipot√©tico', 'gen√©rico', 'placeholder', 'template',
            'dados_insuficientes', 'n√£o dispon√≠vel'
        ]

        # Converte an√°lise para string
        analysis_str = json.dumps(analysis, ensure_ascii=False).lower()

        # Verifica indicadores de simula√ß√£o
        for indicator in simulation_indicators:
            if indicator in analysis_str:
                logger.error(f"‚ùå Indicador de simula√ß√£o encontrado: {indicator}")
                return True

        # Verifica se se√ß√µes obrigat√≥rias est√£o presentes e substanciais
        required_sections = ['avatar_ultra_detalhado', 'escopo', 'insights_exclusivos']
        for section in required_sections:
            if section not in analysis or not analysis[section]:
                logger.error(f"‚ùå Se√ß√£o obrigat√≥ria ausente ou vazia: {section}")
                return True

        # Verifica se insights s√£o substanciais
        insights = analysis.get('insights_exclusivos', [])
        if len(insights) < 15:
            logger.error(f"‚ùå Insights insuficientes: {len(insights)} < 15")
            return True

        return False

    def _validate_ai_response(self, ai_analysis: Dict[str, Any]) -> bool:
        """Valida resposta da IA - FALHA SE INSUFICIENTE"""

        if not ai_analysis or not isinstance(ai_analysis, dict):
            return False

        # Verifica se√ß√µes obrigat√≥rias
        required_sections = [
            'avatar_ultra_detalhado', 'escopo', 'analise_concorrencia_detalhada',
            'estrategia_palavras_chave', 'metricas_performance_detalhadas',
            'funil_vendas_detalhado', 'plano_acao_detalhado', 'insights_exclusivos'
        ]

        for section in required_sections:
            if section not in ai_analysis or not ai_analysis[section]:
                logger.error(f"‚ùå Se√ß√£o obrigat√≥ria ausente: {section}")
                return False

        return True

    def _generate_real_mental_drivers(
        self, 
        ai_analysis: Dict[str, Any], 
        data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Gera drivers mentais customizados REAIS"""

        try:
            avatar_data = ai_analysis.get('avatar_ultra_detalhado', {})

            if not avatar_data:
                raise Exception("AVATAR INSUFICIENTE: N√£o √© poss√≠vel gerar drivers sem avatar detalhado")

            # Usa o Mental Drivers Architect
            drivers_system = mental_drivers_architect.generate_complete_drivers_system(
                avatar_data, data
            )

            if not drivers_system or not drivers_system.get('drivers_customizados'):
                raise Exception("DRIVERS FALHARAM: Sistema de drivers mentais n√£o funcionou")

            return drivers_system

        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar drivers mentais: {str(e)}")
            raise Exception(f"DRIVERS MENTAIS FALHARAM: {str(e)}")

    def _generate_real_visual_proofs(
        self, 
        ai_analysis: Dict[str, Any], 
        data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Gera provas visuais instant√¢neas REAIS"""

        try:
            # Extrai conceitos que precisam de prova visual
            concepts_to_prove = self._extract_concepts_for_visual_proof(ai_analysis, data)

            if not concepts_to_prove:
                raise Exception("CONCEITOS INSUFICIENTES: N√£o h√° conceitos para provar visualmente")

            # Gera provas visuais usando o sistema
            visual_proofs = visual_proofs_generator.generate_complete_proofs_system(
                concepts_to_prove, ai_analysis, data
            )

            if not visual_proofs or len(visual_proofs) < 5:
                raise Exception("PROVAS VISUAIS INSUFICIENTES: Sistema n√£o gerou provas suficientes")

            return visual_proofs

        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar provas visuais: {str(e)}")
            raise Exception(f"PROVAS VISUAIS FALHARAM: {str(e)}")

    def _generate_real_anti_objection(
        self, 
        ai_analysis: Dict[str, Any], 
        data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Gera sistema anti-obje√ß√£o REAL"""

        try:
            avatar_data =